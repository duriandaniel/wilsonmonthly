{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa6090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WAA.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WAM.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WAR.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WAX.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WGB.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WLE.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WMA.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WMI.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-Jan-2025_WMX.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-January-2025_WAA.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-January-2025_WAM.pdf\n",
      "https://wilsonassetmanagement.com.au/wp-content/uploads/2025/02/7.-January-2025_WAR.pdf\n",
      "\n",
      "Total candidates: 207\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from calendar import month_name, month_abbr\n",
    "\n",
    "BASE = \"https://wilsonassetmanagement.com.au/wp-content/uploads\"\n",
    "TICKERS = [\"WAA\",\"WAM\",\"WAR\",\"WAX\",\"WGB\",\"WLE\",\"WMA\",\"WMI\",\"WMX\"]\n",
    "\n",
    "# July=1 ... June=12\n",
    "def prefix_for_report_month(m):  # m: 1..12\n",
    "    return ((m - 7) % 12) + 1\n",
    "\n",
    "# directory month/year = report month + 1 (wrap year if Dec)\n",
    "def dir_year_month(year, m):\n",
    "    if m == 12:\n",
    "        return year + 1, 1\n",
    "    return year, m + 1\n",
    "\n",
    "# filename month variants: full + abbrev (dedup)\n",
    "def month_variants(m):\n",
    "    full = month_name[m]         # e.g., \"June\"\n",
    "    abbr = month_abbr[m]         # e.g., \"Jun\"\n",
    "    variants = {full}\n",
    "    # Add abbrev if different from full (May == May)\n",
    "    if abbr and abbr != full:\n",
    "        variants.add(abbr)\n",
    "    # Also handle special inconsistencies seen in examples:\n",
    "    # use 3-letter abbrev for long names (Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, Jun, Jul)\n",
    "    # Already covered by month_abbr.\n",
    "    return sorted(variants)\n",
    "\n",
    "def estimate_urls_for_year(year=2025):\n",
    "    urls = []\n",
    "    for report_month in range(1, 13):  # Jan..Dec 2025 reports\n",
    "        prefix = prefix_for_report_month(report_month)\n",
    "        dir_y, dir_m = dir_year_month(year, report_month)\n",
    "        for mv in month_variants(report_month):\n",
    "            for t in TICKERS:\n",
    "                fname = f\"{prefix}.-{mv}-2025_{t}.pdf\"\n",
    "                url = f\"{BASE}/{dir_y:04d}/{dir_m:02d}/{fname}\"\n",
    "                urls.append({\n",
    "                    \"report_year\": year,\n",
    "                    \"report_month\": report_month,\n",
    "                    \"dir_year\": dir_y,\n",
    "                    \"dir_month\": dir_m,\n",
    "                    \"prefix\": prefix,\n",
    "                    \"month_text\": mv,\n",
    "                    \"ticker\": t,\n",
    "                    \"url\": url\n",
    "                })\n",
    "    return urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    candidates = estimate_urls_for_year(2025)\n",
    "    # Show a few examples\n",
    "    for row in candidates[:12]:\n",
    "        print(row[\"url\"])\n",
    "    print(f\"\\nTotal candidates: {len(candidates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816f12a",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Unsupported value: 'temperature' does not support 0 with this model. Only the default (1) value is supported.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# df.to_csv(\"wam_holdings_2025_llm.csv\", index=False)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m codes = \u001b[43mllm_extract_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m codes:\n\u001b[32m    187\u001b[39m     \u001b[38;5;66;03m# log a placeholder if you want visibility of misses\u001b[39;00m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mllm_extract_codes\u001b[39m\u001b[34m(date_label, portfolio, url, text)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk, idx, total \u001b[38;5;129;01min\u001b[39;00m chunk_text(text, MAX_CHARS_PER_CHUNK):\n\u001b[32m    137\u001b[39m     user_prompt = prompt_for_codes(date_label, portfolio, url, chunk)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSYSTEM_MSG\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     raw = resp.choices[\u001b[32m0\u001b[39m].message.content.strip()\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# Strip code fences defensively\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Unsupported value: 'temperature' does not support 0 with this model. Only the default (1) value is supported.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Brute-force WAM candidate report URLs (2025), send each PDF's text to ChatGPT (GPT-5) to\n",
    "extract Top 10 or Top 20 holdings (codes only), and aggregate to a pandas DataFrame.\n",
    "\n",
    "Output columns: date (e.g., 'June-2025'), client ('Wilson Asset Management'),\n",
    "portfolio (ticker like 'WAR'), stock (e.g., 'BHP').\n",
    "\n",
    "Notes:\n",
    "- UNSAFE by request: API key is embedded directly.\n",
    "- We HEAD-check URLs to avoid wasting tokens on 404s.\n",
    "- We chunk PDF text to keep prompts within context limits and union codes from all chunks.\n",
    "- Company names are ignored — only stock codes are returned.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from calendar import month_name, month_abbr\n",
    "from openai import OpenAI\n",
    "\n",
    "# ── Config ──────────────────────────────────────────────────────────────────────\n",
    "MODEL = \"gpt-5\"                       # Use your preferred/latest ChatGPT model\n",
    "BASE = \"https://wilsonassetmanagement.com.au/wp-content/uploads\"\n",
    "YEAR = 2025\n",
    "TICKERS = [\"WAA\",\"WAM\",\"WAR\",\"WAX\",\"WGB\",\"WLE\",\"WMA\",\"WMI\",\"WMX\"]\n",
    "MAX_CHARS_PER_CHUNK = 12000\n",
    "HTTP_TIMEOUT = 45\n",
    "DO_HEAD_CHECK = True  # set False to skip HEAD existence check\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# ── Helpers to generate candidate URLs per your rules ───────────────────────────\n",
    "def prefix_for_report_month(m):  # July=1 ... June=12\n",
    "    return ((m - 7) % 12) + 1\n",
    "\n",
    "def dir_year_month(year, m):     # directory is one month ahead of report\n",
    "    return (year + 1, 1) if m == 12 else (year, m + 1)\n",
    "\n",
    "def month_variants(m):\n",
    "    full = month_name[m]    # e.g. \"June\"\n",
    "    abbr = month_abbr[m]    # e.g. \"Jun\"\n",
    "    out = {full}\n",
    "    if abbr and abbr != full:\n",
    "        out.add(abbr)\n",
    "    return sorted(out)\n",
    "\n",
    "def estimate_urls_for_year(year=YEAR):\n",
    "    rows = []\n",
    "    for report_month in range(1, 13):  # Jan..Dec reports\n",
    "        prefix = prefix_for_report_month(report_month)\n",
    "        dy, dm = dir_year_month(year, report_month)\n",
    "        for mv in month_variants(report_month):\n",
    "            for t in TICKERS:\n",
    "                fname = f\"{prefix}.-{mv}-2025_{t}.pdf\"\n",
    "                url = f\"{BASE}/{dy:04d}/{dm:02d}/{fname}\"\n",
    "                rows.append({\n",
    "                    \"date\": f\"{mv}-2025\",  # display date from filename (e.g., June-2025)\n",
    "                    \"ticker\": t,\n",
    "                    \"url\": url\n",
    "                })\n",
    "    return rows\n",
    "\n",
    "# ── Networking / PDF text ───────────────────────────────────────────────────────\n",
    "def url_exists(url: str) -> bool:\n",
    "    try:\n",
    "        r = requests.head(url, timeout=HTTP_TIMEOUT, allow_redirects=True)\n",
    "        if r.status_code == 200:\n",
    "            return True\n",
    "        # some servers don’t allow HEAD; fall back to GET of minimal bytes\n",
    "        if r.status_code in (403, 405):\n",
    "            g = requests.get(url, stream=True, timeout=HTTP_TIMEOUT)\n",
    "            ok = g.status_code == 200\n",
    "            g.close()\n",
    "            return ok\n",
    "        return False\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "def fetch_pdf_text(url: str) -> str:\n",
    "    r = requests.get(url, timeout=HTTP_TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    with pdfplumber.open(BytesIO(r.content)) as pdf:\n",
    "        parts = []\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            t = page.extract_text(x_tolerance=2, y_tolerance=2, layout=True) or \"\"\n",
    "            parts.append(f\"\\n\\n--- PAGE {i} ---\\n{t}\")\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "def chunk_text(text: str, max_chars: int):\n",
    "    n = math.ceil(len(text) / max_chars) or 1\n",
    "    for i in range(n):\n",
    "        yield text[i*max_chars:(i+1)*max_chars], i+1, n\n",
    "\n",
    "# ── LLM prompt (strict: JSON only, codes only) ──────────────────────────────────\n",
    "SYSTEM_MSG = (\n",
    "    \"You are a strict extraction engine. Output JSON only. No prose, no markdown.\"\n",
    ")\n",
    "\n",
    "def prompt_for_codes(date_label: str, portfolio: str, url: str, text_chunk: str) -> str:\n",
    "    # Company names not required; codes only. Accept Top 10 or Top 20 if present.\n",
    "    return f\"\"\"\n",
    "Extract stock holding codes from this PDF text chunk for the section titled\n",
    "\"Top 10 holdings\" or \"Top 20 holdings\". Return ONLY valid JSON with this shape:\n",
    "\n",
    "{{\n",
    "  \"list_type\": \"Top 10\" | \"Top 20\" | \"None\",\n",
    "  \"codes\": [\"ANZ\",\"BHP\",\"...\"]   // up to 20 codes, uppercase, no $ sign\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If you cannot find a Top 10 or Top 20 holdings list in this chunk, return:\n",
    "  {{\"list_type\": \"None\", \"codes\": []}}\n",
    "- Do NOT include company names.\n",
    "- Do NOT include duplicates.\n",
    "- Codes should be A-Z / 0-9 / '.' / '-' only.\n",
    "- Keep order as seen top-to-bottom if visible.\n",
    "\n",
    "Meta:\n",
    "- date: {date_label}\n",
    "- portfolio: {portfolio}\n",
    "- source_url: {url}\n",
    "\n",
    "TEXT_CHUNK:\n",
    "{text_chunk}\n",
    "\"\"\".strip()\n",
    "\n",
    "def llm_extract_codes(date_label: str, portfolio: str, url: str, text: str) -> list[str]:\n",
    "    \"\"\"Send all chunks; union unique codes. Prefer Top 20 if any chunk reports it.\"\"\"\n",
    "    all_codes = set()\n",
    "    saw_top20 = False\n",
    "    for chunk, idx, total in chunk_text(text, MAX_CHARS_PER_CHUNK):\n",
    "        user_prompt = prompt_for_codes(date_label, portfolio, url, chunk)\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "        # Strip code fences defensively\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = raw.strip(\"`\")\n",
    "            raw = re.sub(r\"^json\", \"\", raw, flags=re.I).strip()\n",
    "        try:\n",
    "            obj = json.loads(raw)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "        lt = str(obj.get(\"list_type\", \"None\"))\n",
    "        codes = obj.get(\"codes\", []) or []\n",
    "        # prioritize top20 if ever seen\n",
    "        if lt.lower() == \"top 20\":\n",
    "            saw_top20 = True\n",
    "        for c in codes:\n",
    "            c = c.strip().upper()\n",
    "            if re.fullmatch(r\"[A-Z0-9.\\-]{1,10}\", c):\n",
    "                all_codes.add(c)\n",
    "    # If we saw Top 20 at least once, keep up to 20; else keep up to 10\n",
    "    final_n = 20 if saw_top20 else 10\n",
    "    return list(sorted(all_codes))[:final_n]\n",
    "\n",
    "# ── Run: generate candidates → filter → extract → DataFrame ─────────────────────\n",
    "def main():\n",
    "    candidates = estimate_urls_for_year(YEAR)\n",
    "    rows = []\n",
    "    for item in candidates:\n",
    "        date_label = item[\"date\"]        # e.g., \"June-2025\"\n",
    "        ticker = item[\"ticker\"]          # portfolio code, e.g., \"WAR\"\n",
    "        url = item[\"url\"]\n",
    "\n",
    "        if DO_HEAD_CHECK and not url_exists(url):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            text = fetch_pdf_text(url)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        codes = llm_extract_codes(date_label, ticker, url, text)\n",
    "        if not codes:\n",
    "            # log a placeholder if you want visibility of misses\n",
    "            continue\n",
    "\n",
    "        for code in codes:\n",
    "            rows.append({\n",
    "                \"date\": date_label,\n",
    "                \"client\": \"Wilson Asset Management\",\n",
    "                \"portfolio\": ticker,\n",
    "                \"stock\": code,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"date\",\"client\",\"portfolio\",\"stock\"])\n",
    "    print(df)\n",
    "    # df.to_csv(\"wam_holdings_2025_llm.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a806638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
