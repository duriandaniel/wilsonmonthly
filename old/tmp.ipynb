{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b6487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct pattern result:\n",
      "                      firm portfolio      date code  \\\n",
      "0  Wilson Asset Management       WMX  Sep-2025  ANZ   \n",
      "1  Wilson Asset Management       WMX  Sep-2025  BHP   \n",
      "2  Wilson Asset Management       WMX  Sep-2025  CGF   \n",
      "3  Wilson Asset Management       WMX  Sep-2025  CSL   \n",
      "4  Wilson Asset Management       WMX  Sep-2025  NAB   \n",
      "5  Wilson Asset Management       WMX  Sep-2025  ORA   \n",
      "6  Wilson Asset Management       WMX  Sep-2025  RIO   \n",
      "7  Wilson Asset Management       WMX  Sep-2025  SGP   \n",
      "8  Wilson Asset Management       WMX  Sep-2025  WBC   \n",
      "9  Wilson Asset Management       WMX  Sep-2025  WTC   \n",
      "\n",
      "                                             company  \n",
      "0                                 ANZ Group Holdings  \n",
      "1                                          BHP Group  \n",
      "2                                         Challenger  \n",
      "3                                                CSL  \n",
      "4                            National Australia Bank  \n",
      "5                                              Orora  \n",
      "6                                          Rio Tinto  \n",
      "7                                          Stockland  \n",
      "8  Westpac Banking Corporation Momentum Value Qua...  \n",
      "9                                    WiseTech Global  \n",
      "\n",
      "Parts pattern result:\n",
      "                      firm portfolio        date code  \\\n",
      "0  Wilson Asset Management       WMX  2025-09-30  ANZ   \n",
      "1  Wilson Asset Management       WMX  2025-09-30  BHP   \n",
      "2  Wilson Asset Management       WMX  2025-09-30  CGF   \n",
      "3  Wilson Asset Management       WMX  2025-09-30  CSL   \n",
      "4  Wilson Asset Management       WMX  2025-09-30  NAB   \n",
      "5  Wilson Asset Management       WMX  2025-09-30  ORA   \n",
      "6  Wilson Asset Management       WMX  2025-09-30  RIO   \n",
      "7  Wilson Asset Management       WMX  2025-09-30  SGP   \n",
      "8  Wilson Asset Management       WMX  2025-09-30  WBC   \n",
      "9  Wilson Asset Management       WMX  2025-09-30  WTC   \n",
      "\n",
      "                                             company  \n",
      "0                                 ANZ Group Holdings  \n",
      "1                                          BHP Group  \n",
      "2                                         Challenger  \n",
      "3                                                CSL  \n",
      "4                            National Australia Bank  \n",
      "5                                              Orora  \n",
      "6                                          Rio Tinto  \n",
      "7                                          Stockland  \n",
      "8  Westpac Banking Corporation Momentum Value Qua...  \n",
      "9                                    WiseTech Global  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "def _fetch_pdf_bytes(url: str) -> BytesIO:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return BytesIO(r.content)\n",
    "\n",
    "def _extract_full_text(pdf_bytes: BytesIO) -> str:\n",
    "    chunks = []\n",
    "    with pdfplumber.open(pdf_bytes) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            chunks.append(page.extract_text() or \"\")\n",
    "    return \"\\n\".join(chunks)\n",
    "\n",
    "def _slice_top10_block(full_text: str) -> str:\n",
    "    # start markers are loose on purpose\n",
    "    for pat in [r\"Top\\s+10\\s+equity\\s+holdings.*\", r\"Top\\s+10\\s+holdings.*\"]:\n",
    "        m = re.search(pat, full_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        if m:\n",
    "            start = m.start()\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"Top 10 holdings section not found.\")\n",
    "\n",
    "    # end markers\n",
    "    tail_markers = [\n",
    "        r\"\\n\\s*Equity portfolio factor exposure\",\n",
    "        r\"\\n\\s*WAM Income Maximiser Limited\",\n",
    "        r\"\\n\\s*October 2025\",\n",
    "        r\"\\n\\s*Our proven investment process\",\n",
    "        r\"\\n\\s*About the\\s+Investment Manager\",\n",
    "    ]\n",
    "    end_positions = []\n",
    "    for pat in tail_markers:\n",
    "        m2 = re.search(pat, full_text[start:], flags=re.IGNORECASE)\n",
    "        if m2:\n",
    "            end_positions.append(start + m2.start())\n",
    "    end = min(end_positions) if end_positions else len(full_text)\n",
    "    return full_text[start:end]\n",
    "\n",
    "def _parse_holdings(block: str):\n",
    "    holdings = []\n",
    "    for line in block.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or re.search(r\"Code\\s+Company\\s+Name\", line, flags=re.IGNORECASE):\n",
    "            continue\n",
    "        m = re.match(r\"^([A-Z]{2,5})\\s+(.*)$\", line)\n",
    "        if not m:\n",
    "            continue\n",
    "        code, rest = m.group(1), m.group(2).strip()\n",
    "        tokens = rest.split()\n",
    "        while tokens and re.match(r\"^[+-]?\\d+(\\.\\d+)?x?$\", tokens[-1], flags=re.IGNORECASE):\n",
    "            tokens.pop()\n",
    "        company = \" \".join(tokens).strip()\n",
    "        if code and company:\n",
    "            holdings.append((code, company))\n",
    "    return holdings\n",
    "\n",
    "def parse_wmx_top10(url: str, date_label: str, accumulator_df: pd.DataFrame | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts Top 10 holdings from a WMX PDF and appends to accumulator_df.\n",
    "    date_label is a string you control, e.g. '2025-09-30' or 'Sep-2025'.\n",
    "    \"\"\"\n",
    "    pdf_bytes = _fetch_pdf_bytes(url)\n",
    "    text = _extract_full_text(pdf_bytes)\n",
    "    block = _slice_top10_block(text)\n",
    "    parsed = _parse_holdings(block)\n",
    "\n",
    "    # keep first 10 unique by code\n",
    "    seen, top10 = set(), []\n",
    "    for code, company in parsed:\n",
    "        if code not in seen:\n",
    "            seen.add(code)\n",
    "            top10.append((code, company))\n",
    "        if len(top10) == 10:\n",
    "            break\n",
    "    if not top10:\n",
    "        raise ValueError(\"No holdings parsed. Inspect PDF format.\")\n",
    "\n",
    "    df = pd.DataFrame(top10, columns=[\"code\", \"company\"])\n",
    "    df.insert(0, \"firm\", \"Wilson Asset Management\")\n",
    "    df.insert(1, \"portfolio\", \"WMX\")\n",
    "    df.insert(2, \"date\", date_label)\n",
    "\n",
    "    if accumulator_df is None:\n",
    "        return df\n",
    "    else:\n",
    "        return pd.concat([accumulator_df, df], ignore_index=True)\n",
    "\n",
    "def run_for_dates(dates: list[str], url_pattern: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dates: list of date labels you want to use as 'date' column.\n",
    "    url_pattern: a Python format string that yields the PDF URL for each date.\n",
    "      You can use either {date} directly or strftime codes via a parsed datetime.\n",
    "\n",
    "    Two usage modes:\n",
    "    1) If your date strings are like '2025-09-30', the pattern can use strftime:\n",
    "       url_pattern = \"https://.../{month_abr}-{year}_WMX.pdf\"\n",
    "       Build those fields below.\n",
    "\n",
    "    2) If you already embedded the exact date text in each string and the pattern\n",
    "       just inserts {date}, use only {date}.\n",
    "\n",
    "    This function tries both. If '{date}' in pattern, it uses that directly.\n",
    "    Otherwise it parses the string as YYYY-MM-DD and exposes {year}, {month}, {month_abr}.\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    for d in dates:\n",
    "        if \"{date}\" in url_pattern:\n",
    "            url = url_pattern.format(date=d)\n",
    "            date_label = d\n",
    "        else:\n",
    "            # parse ISO date\n",
    "            dt = datetime.fromisoformat(d)\n",
    "            ctx = {\n",
    "                \"year\": dt.strftime(\"%Y\"),\n",
    "                \"month\": dt.strftime(\"%m\"),\n",
    "                \"month_name\": dt.strftime(\"%B\"),\n",
    "                \"month_abr\": dt.strftime(\"%b\"),\n",
    "            }\n",
    "            url = url_pattern.format(**ctx)\n",
    "            date_label = dt.strftime(\"%Y-%m-%d\")\n",
    "        out = parse_wmx_top10(url, date_label, out)\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: direct full URLs per month using {date}\n",
    "    dates = [\"Sep-2025\"]  # labels you want in the output\n",
    "    pattern_direct = \"https://wilsonassetmanagement.com.au/wp-content/uploads/2025/10/3.-{date}_WMX.pdf\"\n",
    "    df1 = run_for_dates(dates, pattern_direct)\n",
    "    print(\"Direct pattern result:\")\n",
    "    print(df1)\n",
    "\n",
    "    # Example 2: build from ISO dates using strftime parts\n",
    "    # Adjust folder logic if their folder naming changes by month.\n",
    "    iso_dates = [\"2025-09-30\"]\n",
    "    pattern_from_parts = \"https://wilsonassetmanagement.com.au/wp-content/uploads/2025/10/3.-{month_abr}-2025_WMX.pdf\"\n",
    "    df2 = run_for_dates(iso_dates, pattern_from_parts)\n",
    "    print(\"\\nParts pattern result:\")\n",
    "    print(df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
